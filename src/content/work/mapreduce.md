---
title: "mapreduce"
publishDate: "2025-09-14 01:00:00"
img: /tymultiverse/assets/algorithm.jpg
img_alt: A bright pink sheet of paper used to wrap flowers curves in front of rich blue background
description: MapReduce åˆ†å¸ƒå¼è¨ˆç®—æ¨¡å‹æ·±åº¦å‰–æï¼šå¾ Unix ç®¡ç·šåˆ°å¤§æ•¸æ“šè™•ç†çš„å®Œæ•´æ¼”é€²
tags:
  - Big Data
  - Distributed Computing
  - MapReduce
  - Hadoop
  - HDFS
  - Data Processing
---

MapReduce å®Œæ•´è§£è®€ï¼šå¾ Unixã€Producer-Consumer åˆ° JavaScript çš„å°ç…§

åœ¨å¤§æ•¸æ“šç³»çµ±ä¸­ï¼ŒMapReduce æ˜¯æœ€å…·ä»£è¡¨æ€§çš„è¨ˆç®—æ¨¡å‹ä¹‹ä¸€ã€‚å®ƒçœ‹ä¼¼è¤‡é›œï¼Œå…¶å¯¦æ ¸å¿ƒæ€æƒ³èˆ‡æˆ‘å€‘æ—¥å¸¸ç”¨éçš„ Unix å·¥å…·ã€Producer-Consumer æ¨¡å¼ã€ç”šè‡³ JavaScript çš„ map/reduce æ–¹æ³• éƒ½æœ‰å…±é€šä¹‹è™•ã€‚æœ¬æ–‡å°‡å¾é€™äº›ç†Ÿæ‚‰çš„æ¦‚å¿µå‡ºç™¼ï¼Œé€æ­¥æ‹†è§£ MapReduce çš„æœ¬è³ªã€‚

## 1. MapReduce æ˜¯ä»€éº¼ï¼Ÿ

MapReduce å¯ä»¥ç°¡å–®ç†è§£ç‚ºï¼š

**Mapï¼ˆæ˜ å°„ï¼‰**ï¼šé€ç­†è™•ç†è³‡æ–™ï¼Œè½‰æ›æˆ (key, value) å°ã€‚

**Reduceï¼ˆæ­¸ç´„ï¼‰**ï¼šå°‡ç›¸åŒ key çš„å€¼èšåˆèµ·ä¾†ï¼Œç”¢ç”Ÿçµæœã€‚

èˆ‰ä¾‹ä¾†èªªï¼Œè‹¥è¦è¨ˆç®— Web log ä¸­æœ€ç†±é–€çš„ URLï¼š

**Map**ï¼šè¼¸å…¥æ¯ä¸€è¡Œ logï¼Œå–å‡º URL â†’ (url, 1)ã€‚

**Shuffle**ï¼šç³»çµ±è‡ªå‹•å°‡ç›¸åŒ URL çš„ç´€éŒ„åˆ†çµ„åœ¨ä¸€èµ·ã€‚

**Reduce**ï¼šå°æ¯çµ„ (url, 1) ç´¯åŠ  â†’ (url, count)ã€‚

é€™å’Œæˆ‘å€‘åœ¨ Linux ä¸‹ç”¨ç®¡ç·šè™•ç†æ—¥èªŒå¹¾ä¹ä¸€æ¨£ï¼š

```bash
cat access.log | awk '{print $7}' | sort | uniq -c | sort -nr
```

å·®åˆ¥æ˜¯ MapReduce å¯ä»¥åŒæ™‚åœ¨ä¸Šåƒå°æ©Ÿå™¨ä¸Šä¸¦è¡Œé‹ç®—ï¼Œè™•ç†å–®æ©Ÿæ ¹æœ¬å¡ä¸ä¸‹çš„è³‡æ–™é‡ã€‚

## 2. åˆ†å¸ƒå¼æ–‡ä»¶ç³»çµ± HDFS

MapReduce çš„å¼·å¤§ï¼Œä¾†è‡ªæ–¼å®ƒå’Œ **åˆ†å¸ƒå¼æ–‡ä»¶ç³»çµ± HDFS** çš„çµåˆã€‚
HDFS çš„é‹ä½œæ–¹å¼ï¼š

- æª”æ¡ˆæœƒè¢«åˆ‡æˆæ•¸ç™¾ MB çš„ã€Œæª”æ¡ˆå€å¡Šã€ï¼Œåˆ†æ•£å­˜æ”¾åœ¨ä¸åŒæ©Ÿå™¨çš„ç¡¬ç¢Ÿã€‚
- NameNode è² è²¬è¨˜éŒ„ã€Œå“ªå€‹å€å¡Šåœ¨å“ªå°æ©Ÿå™¨ã€ã€‚
- ç‚ºäº†é˜²æ­¢æ•…éšœï¼Œæ¯å€‹å€å¡Šæœƒæœ‰å¤šä»½å‰¯æœ¬ï¼Œåˆ†ä½ˆåœ¨ä¸åŒæ©Ÿå™¨ã€‚

é€™æ¨£çš„è¨­è¨ˆï¼Œè®“æˆ‘å€‘èƒ½å¤ ç”¨ã€Œè¨±å¤šä¾¿å®œçš„æ™®é€šæ©Ÿå™¨ã€æ‹¼æ¹Šå‡ºè¶…å¤§å„²å­˜ç³»çµ±ï¼Œè€Œä¸æ˜¯ä¾è³´æ˜‚è²´çš„å°ˆç”¨å­˜å„²ã€‚

## 3. MapReduce çš„åŸ·è¡Œæµç¨‹

ä»¥ä¸‹æ˜¯ MapReduce çš„å®Œæ•´é‹è¡Œæ­¥é©Ÿï¼š

1. **è¼¸å…¥åˆ‡åˆ†**ï¼šå¤§æª”æ¡ˆåˆ‡æˆå¤šå€‹å€å¡Šï¼Œæ¯å€‹å€å¡Šåˆ†é…ä¸€å€‹ Map Taskã€‚
2. **Map éšæ®µ**ï¼šMapper è™•ç†è‡ªå·±çš„å€å¡Šï¼Œè¼¸å‡º (key, value)ã€‚
3. **Shuffleï¼ˆæ´—ç‰Œï¼‰**ï¼šç³»çµ±è‡ªå‹•æ ¹æ“š keyï¼ŒæŠŠè³‡æ–™åˆ†æ´¾åˆ°å°æ‡‰çš„ Reducerï¼Œä¸¦ä¸”æ’åºã€‚
4. **Reduce éšæ®µ**ï¼šReducer èšåˆåŒä¸€å€‹ key çš„æ‰€æœ‰ valueï¼Œç”¢ç”Ÿçµæœã€‚
5. **è¼¸å‡º**ï¼šçµæœå¯«å› HDFSï¼Œåˆ†æ•£æˆå¤šå€‹æª”æ¡ˆã€‚

ğŸ‘‰ ç°¡å–®æ¯”å–»ï¼š

- **Map** = è€å¸«æ‰¹æ”¹è‡ªå·±ç­ç´šçš„è©¦å·ã€‚
- **Shuffle** = æŠŠåŒä¸€ç§‘ç›®çš„è©¦å·é›†ä¸­çµ¦ä¸€ä½ç§‘ç›®è€å¸«ã€‚
- **Reduce** = è©²ç§‘ç›®è€å¸«çµ±è¨ˆæˆç¸¾ï¼Œç”Ÿæˆæˆç¸¾è¡¨ã€‚

## 4. èˆ‡ Producer-Consumer çš„æ¯”è¼ƒ

MapReduce çš„æµç¨‹å’Œ **Producer-Consumer æ¨¡å¼** ä¹Ÿå¾ˆç›¸ä¼¼ï¼š

| å…ƒä»¶ | MapReduce | Producer-Consumer |
|------|-----------|-------------------|
| Producer | Map ä»»å‹™ï¼Œç”¢ç”Ÿ (key, value) | Producerï¼Œç”¢ç”Ÿä»»å‹™ |
| Queue / Broker | Shuffleï¼Œåˆ†å€ & æ’åº & å‚³è¼¸ | ä»»å‹™ä½‡åˆ— |
| Consumer | Reduce ä»»å‹™ï¼Œèšåˆçµæœ | Consumerï¼Œè™•ç†ä»»å‹™ |

ä½†ä¹Ÿæœ‰å·®ç•°ï¼š

- **Shuffle æ›´è°æ˜**ï¼šä¸åªæ˜¯å‚³è¼¸ï¼Œé‚„è¦ç¢ºä¿åŒä¸€å€‹ key çš„è³‡æ–™é›†ä¸­åˆ°åŒä¸€ Reducerï¼Œä¸¦æ’å¥½åºã€‚
- **MapReduce æ˜¯æ‰¹æ¬¡**ï¼šå¿…é ˆç­‰ Map ä»»å‹™çµæŸï¼ŒReduce æ‰èƒ½é–‹å§‹ï¼›Producer-Consumer å‰‡å¯å³æ™‚æµå¼è™•ç†ã€‚

ğŸ‘‰ å¯ä»¥èªªï¼š**MapReduce = åŠ å¼·ç‰ˆçš„ Producer-Consumerï¼Œå…§å»ºåˆ†æµã€æ’åºã€èšåˆæ©Ÿåˆ¶**ã€‚

## 5. èˆ‡ JavaScript çš„ map/reduce æ–¹æ³•æ¯”è¼ƒ

å¾ˆå¤šäººå­¸é JavaScript çš„ `map()` å’Œ `reduce()`ï¼Œé€™è®“ç†è§£ MapReduce æ›´å®¹æ˜“ã€‚

### JavaScript ç¯„ä¾‹
```javascript
const arr = [1, 2, 3, 4];

// mapï¼šå¹³æ–¹
const squared = arr.map(x => x * x);
// [1, 4, 9, 16]

// reduceï¼šåŠ ç¸½
const sum = arr.reduce((acc, x) => acc + x, 0);
// 10
```

### å·®ç•°æ•´ç†

| ç‰¹é» | JS map/reduce | Hadoop MapReduce |
|------|---------------|------------------|
| è³‡æ–™è¦æ¨¡ | é™£åˆ—ï¼ˆå°ï¼Œæ”¾å¾—ä¸‹è¨˜æ†¶é«”ï¼‰ | PB ç´šï¼ˆåˆ†æ•£åœ¨ä¸Šè¬å°æ©Ÿå™¨ï¼‰ |
| åŸ·è¡Œç’°å¢ƒ | å–®æ©Ÿè¨˜æ†¶é«” | åˆ†å¸ƒå¼å¢é›† |
| Map | é™£åˆ—é€ç­†è½‰æ› | æ¯å°æ©Ÿå™¨è™•ç†ä¸€å€‹æª”æ¡ˆå€å¡Š |
| Reduce | èšåˆæˆå–®ä¸€å€¼ | èšåˆåŒä¸€ key çš„å€¼ï¼Œè¼¸å‡ºåˆ°å¤šå€‹æª”æ¡ˆ |
| æ’åº/åˆ†æµ | æ²’æœ‰ | å…§å»º shuffleï¼Œç¢ºä¿åŒ key åŒè™•ç† |
| å³æ™‚æ€§ | å³æ™‚ | æ‰¹æ¬¡è™•ç† |

## 6. èˆ‡ Java Stream API çš„æ¯”è¼ƒ

Java é–‹ç™¼è€…å¯ä»¥é€šé **Java 8 Stream API** ä¾†ç†è§£ MapReduce çš„æ¦‚å¿µã€‚Stream API æä¾›äº†å‡½æ•¸å¼ç·¨ç¨‹é¢¨æ ¼çš„æ•¸æ“šè™•ç†æ–¹å¼ã€‚

### Java Stream ç¯„ä¾‹
```java
import java.util.Arrays;
import java.util.List;
import java.util.stream.Collectors;

public class StreamExample {
    public static void main(String[] args) {
        List<Integer> numbers = Arrays.asList(1, 2, 3, 4);

        // mapï¼šå¹³æ–¹
        List<Integer> squared = numbers.stream()
            .map(x -> x * x)
            .collect(Collectors.toList());
        // [1, 4, 9, 16]

        // reduceï¼šåŠ ç¸½
        int sum = numbers.stream()
            .reduce(0, (acc, x) -> acc + x);
        // 10

        // è¤‡é›œç¯„ä¾‹ï¼šæ–‡å­—è™•ç†
        List<String> words = Arrays.asList("hello", "world", "java", "stream");

        // çµ±è¨ˆå–®è©é•·åº¦åˆ†ä½ˆ
        Map<Integer, Long> lengthCount = words.stream()
            .collect(Collectors.groupingBy(
                String::length,
                Collectors.counting()
            ));
        // {5=2, 4=1, 6=1}
    }
}
```

### Java MapReduce å¯¦ç¾ç¯„ä¾‹
```java
import org.apache.hadoop.mapreduce.*;
import org.apache.hadoop.io.*;

public class WordCountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(LongWritable key, Text value, Context context)
            throws IOException, InterruptedException {
        String line = value.toString();
        StringTokenizer tokenizer = new StringTokenizer(line);

        while (tokenizer.hasMoreTokens()) {
            word.set(tokenizer.nextToken());
            context.write(word, one);  // Map: (word, 1)
        }
    }
}

public class WordCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
    public void reduce(Text key, Iterable<IntWritable> values, Context context)
            throws IOException, InterruptedException {
        int sum = 0;
        for (IntWritable val : values) {
            sum += val.get();
        }
        context.write(key, new IntWritable(sum));  // Reduce: (word, count)
    }
}
```

### Java èˆ‡å…¶ä»–æŠ€è¡“çš„æ¯”è¼ƒ

| ç‰¹é» | Java Stream | Java MapReduce | Hadoop MapReduce |
|------|-------------|----------------|------------------|
| è³‡æ–™è¦æ¨¡ | é›†åˆï¼ˆä¸­ç­‰è¦æ¨¡ï¼‰ | å¤§è³‡æ–™é›† | PB ç´šåˆ†å¸ƒå¼ |
| åŸ·è¡Œç’°å¢ƒ | JVM å–®æ©Ÿ | JVM åˆ†å¸ƒå¼ | è·¨æ©Ÿå™¨åˆ†å¸ƒå¼ |
| ä¸¦è¡ŒåŒ– | å…§å»ºä¸¦è¡Œæµ | æ‰‹å‹•é…ç½® | è‡ªå‹•è² è¼‰å¹³è¡¡ |
| å®¹éŒ¯æ€§ | ç„¡ | åŸºæœ¬å®¹éŒ¯ | é«˜å¯ç”¨å®¹éŒ¯ |
| å­¸ç¿’æ›²ç·š | ä½ | ä¸­ç­‰ | é«˜ |
| é©ç”¨å ´æ™¯ | è³‡æ–™è™•ç†ç®¡é“ | å¤§æ•¸æ“šæ‰¹æ¬¡è™•ç† | æµ·é‡æ•¸æ“šåˆ†æ |

### Java MapReduce çš„å„ªå‹¢

1. **é¡å‹å®‰å…¨**ï¼šç·¨è­¯æ™‚æª¢æŸ¥ï¼Œæ¸›å°‘é‹è¡Œæ™‚éŒ¯èª¤
2. **æ€§èƒ½å„ªåŒ–**ï¼šJVM å„ªåŒ– + åˆ†å¸ƒå¼è™•ç†
3. **ç”Ÿæ…‹ç³»çµ±**ï¼šHadoop/Spark ç”Ÿæ…‹è±å¯Œ
4. **ä¼æ¥­æ‡‰ç”¨**ï¼šå»£æ³›ç”¨æ–¼ç”Ÿç”¢ç’°å¢ƒ

ğŸ‘‰ **å­¸ç¿’å»ºè­°**ï¼šå¾ Java Stream API é–‹å§‹ç†è§£å‡½æ•¸å¼æ•¸æ“šè™•ç†ï¼Œå†é€²éšåˆ° Hadoop MapReduceï¼Œæœ€å¾ŒæŒæ¡ Spark ç­‰æ–°ä¸–ä»£æ¡†æ¶ã€‚